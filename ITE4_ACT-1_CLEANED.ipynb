{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "b844748e668a43539145d1cdf6ab0b89",
            "b10793728e624428ab770dfbea01cab5",
            "c59827d418b647cfae89c468d66b7044",
            "b8537ddfa28c43c1abb9340302f1b549",
            "94b270cf04b24cae9990536c53e1472e",
            "04ad9b4be8df49828b43e8d2343307db",
            "8017f778d1e94cd486fc867bc4996b95",
            "9a44efa4ff414d59972af27500b67401",
            "4bac7a4879294a619611db5ad7f4c337",
            "5ae766b7a50a481e8500892d3d831cae",
            "551bdbc0f28f458ea25d83dc230a5d18"
          ]
        },
        "id": "2YgeXzOkpRR-",
        "outputId": "592ee649-1788-4dff-8c46-136307a24203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, using CPU.\n",
            "\n",
            "--- Loading and Preprocessing Data ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-554d7964-2f91-4551-95d9-5f9d0176fc9b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-554d7964-2f91-4551-95d9-5f9d0176fc9b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving clickbait_data.csv to clickbait_data (5).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b844748e668a43539145d1cdf6ab0b89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['headline', 'clickbait'],\n",
            "        num_rows: 32000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from google.colab import files\n",
        "\n",
        "# Ensure GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU.\")\n",
        "\n",
        "print(\"\\n--- Loading and Preprocessing Data ---\")\n",
        "\n",
        "# Upload the CSV from your computer\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Replace with your actual filename if it's different\n",
        "dataset = load_dataset(\"csv\", data_files=list(uploaded.keys()))\n",
        "print(dataset)\n",
        "\n",
        "# Split into train/test\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "train_data = dataset[\"train\"].select(range(min(2000, len(dataset[\"train\"]))))\n",
        "eval_data = dataset[\"test\"].select(range(min(500, len(dataset[\"test\"]))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Tokenizer (the pre-processing tool)\n",
        "MODEL_NAME = \"distilbert-base-multilingual-cased\"\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # This prepares the text and converts it into numerical IDs that the model understands\n",
        "    return tokenizer(examples[\"headline\"], truncation=True, padding=True)\n",
        "\n",
        "# Apply tokenization to the training and evaluation sets\n",
        "tokenized_train = train_data.map(tokenize_function, batched=True)\n",
        "tokenized_eval = eval_data.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set the format to PyTorch tensors\n",
        "tokenized_train.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])\n",
        "tokenized_eval.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "070251cb1df54c89a7c0ad1283dec147",
            "66d598e3623547f8abdec33bfaf276a7",
            "9b8d1614e2d94092beaaf403831abd69",
            "138cf87dc51044259fd32ef7b074e334",
            "01cc4be2a76f480e9870172fce5a062f",
            "986cbeb46b504a8eaf5d317974e8f759",
            "c1ef2c374b81457ca3064b16ff1dddcb",
            "5fa34887d8ce4373b54fafea9af2be6f",
            "75de5802d713441b8e838d23fc52f5f5",
            "3d4aedc7bfab4356bacbf1737706ada0",
            "41d3c23fa6f14fa2bf7b78cc8c56a1f6",
            "3419d3a1a68a4c73b53ce94d308fe235",
            "adcab456f95e49fcb8fa01fb1b04b81e",
            "c540fabc17d54549b6096e00d93f8398",
            "03e5d8dd4cd741f9ad0d9746b33b671c",
            "dfa2833f8a6f409aa1038783f741a498",
            "ddfbb4707697412c8333a7bc131dc75b",
            "7ede88cc283b4796919a03612daba0c6",
            "5d00fcb235c347b088f7aea99bbde0ac",
            "c59f6bf97fe54a51b293139deca3ee83",
            "1b68e97778c1497389a045ae7d8cf66e",
            "83ea8b37c7e84958a2642a64822f8685"
          ]
        },
        "id": "4GHh13L8ppI1",
        "outputId": "ac7d8b5a-27c3-42e4-96a9-14da91858b8b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "070251cb1df54c89a7c0ad1283dec147"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3419d3a1a68a4c73b53ce94d308fe235"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. MODEL DEFINITION (Stage 3 Analog) ---\n",
        "\n",
        "# Load the pre-trained DistilBERT model for sequence classification (sentiment analysis)\n",
        "# The model automatically head for 2 classes (positive/negative)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to(device)\n",
        "print(f\"Model loaded: {MODEL_NAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "2bfb0d4b91a64c3f825d8f18dfa6b86b",
            "930d5856458e4ff18b32f86a502f4355",
            "3793794e40a04a31831dd1980e630290",
            "84064eea0a424be7a86aedb1df4f2783",
            "171a49b81e7242bbb00890553e79e7f6",
            "b4a8d9c6cea4482f890a53cd0620c680",
            "e5bfd0b57aab487598ff925efaff735b",
            "76ade2dc3f874b71b82af930dd1ac8c7",
            "54a2e7c51e9248ee918de0e32d326db1",
            "36ced9b47b904ba6974f49fbe6fe4e7e",
            "10e629992bae45378a8ef9887bb64f1f"
          ]
        },
        "id": "9Vz8OloCqEaV",
        "outputId": "1eeee25d-1b10-40cb-c764-190bf813f90a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bfb0d4b91a64c3f825d8f18dfa6b86b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: distilbert-base-multilingual-cased\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# --- Compute Metrics Function ---\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    f1 = f1_score(p.label_ids, preds, average=\"binary\")\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "# --- Define Experiments (only 3 hyperparameters assigned to you) ---\n",
        "EXPERIMENTS = [\n",
        "    {\"num_train_epochs\": 2, \"per_device_train_batch_size\": 16, \"weight_decay\": 0.01},\n",
        "    {\"num_train_epochs\": 4, \"per_device_train_batch_size\": 32, \"weight_decay\": 0.05},\n",
        "    {\"num_train_epochs\": 6, \"per_device_train_batch_size\": 64, \"weight_decay\": 0.1},\n",
        "]\n",
        "\n",
        "results_list = []\n",
        "\n",
        "for i, exp in enumerate(EXPERIMENTS, start=1):\n",
        "    print(f\"\\n--- Running Experiment {i}: {exp} ---\")\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_exp_{i}\",\n",
        "        num_train_epochs=exp[\"num_train_epochs\"],\n",
        "        per_device_train_batch_size=exp[\"per_device_train_batch_size\"],\n",
        "        per_device_eval_batch_size=16,\n",
        "        weight_decay=exp[\"weight_decay\"],\n",
        "        warmup_steps=500,\n",
        "        logging_dir=f\"./logs_exp_{i}\",\n",
        "        logging_steps=100,\n",
        "        eval_strategy=\"epoch\",     # <- your transformers version supports eval_strategy\n",
        "        save_strategy=\"epoch\",     # must match eval_strategy\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        report_to=[],              # disable external logging like WandB\n",
        "    )\n",
        "\n",
        "    # Initialize the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    # Train & evaluate\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    print(f\"Experiment Results: {eval_results}\")\n",
        "\n",
        "    results_list.append({\n",
        "        \"num_train_epochs\": exp[\"num_train_epochs\"],\n",
        "        \"per_device_train_batch_size\": exp[\"per_device_train_batch_size\"],\n",
        "        \"weight_decay\": exp[\"weight_decay\"],\n",
        "        \"accuracy\": eval_results.get(\"eval_accuracy\"),\n",
        "        \"f1\": eval_results.get(\"eval_f1\")\n",
        "    })\n",
        "\n",
        "# --- Export Results to Excel ---\n",
        "results_df = pd.DataFrame(results_list)\n",
        "results_df.to_excel(\"/content/drive/MyDrive/experiment_results.xlsx\", index=False)\n",
        "print(\"\\n\u2705 Results exported successfully to your Google Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OPWVbDnXqHpu",
        "outputId": "4182daa6-8787-4e3f-e8ea-a620d2e30611"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "--- Running Experiment 1: {'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 0.01} ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3594931058.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 15:19, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.016505</td>\n",
              "      <td>0.998000</td>\n",
              "      <td>0.998020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022098</td>\n",
              "      <td>0.996000</td>\n",
              "      <td>0.996047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:26]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment Results: {'eval_loss': 0.016504881903529167, 'eval_accuracy': 0.998, 'eval_f1': 0.998019801980198, 'eval_runtime': 26.9196, 'eval_samples_per_second': 18.574, 'eval_steps_per_second': 1.189, 'epoch': 2.0}\n",
            "\n",
            "--- Running Experiment 2: {'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.05} ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3594931058.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [252/252 27:51, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.060653</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>0.992126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066418</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>0.994083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.073979</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>0.994083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079804</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>0.994083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:26]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment Results: {'eval_loss': 0.06065290421247482, 'eval_accuracy': 0.992, 'eval_f1': 0.9921259842519685, 'eval_runtime': 26.7996, 'eval_samples_per_second': 18.657, 'eval_steps_per_second': 1.194, 'epoch': 4.0}\n",
            "\n",
            "--- Running Experiment 3: {'num_train_epochs': 6, 'per_device_train_batch_size': 64, 'weight_decay': 0.1} ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3594931058.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [192/192 40:08, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.062303</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>0.992126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.027209</td>\n",
              "      <td>0.996000</td>\n",
              "      <td>0.996047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.045205</td>\n",
              "      <td>0.996000</td>\n",
              "      <td>0.996047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065956</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>0.994083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.073061</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>0.994083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077176</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>0.994083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:24]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment Results: {'eval_loss': 0.027208801358938217, 'eval_accuracy': 0.996, 'eval_f1': 0.9960474308300395, 'eval_runtime': 25.8303, 'eval_samples_per_second': 19.357, 'eval_steps_per_second': 1.239, 'epoch': 6.0}\n",
            "\n",
            "\u2705 Results exported successfully to your Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# 1. Define the trained model and tokenizer (already from your training)\n",
        "# If you restarted your runtime, you'll need to reload them from a checkpoint instead.\n",
        "# For now, this assumes you still have `model` and `tokenizer` in memory.\n",
        "\n",
        "# 2. Create a prediction pipeline using your fine-tuned model\n",
        "clickbait_detector = pipeline(\n",
        "    \"text-classification\",  # more general task name than 'sentiment-analysis'\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1  # GPU if available\n",
        ")\n",
        "\n",
        "# 3. Example new headlines to test\n",
        "new_headlines = [\n",
        "    \"MMDA Launches New Traffic Scheme to Ease Congestion Along EDSA\",\n",
        "    \"DepEd Confirms Opening of Classes Will Proceed as Scheduled\",\n",
        "    \"DOH Reports Steady Decline in Dengue Cases Nationwide\",\n",
        "    \"You Won\u2019t Believe What This Filipino Celebrity Did After Winning the Lottery!\",\n",
        "    \"This One Trick Can Help You Save Thousands on Your Meralco Bill!\",\n",
        "    \"Students in Manila Tried This Study Method\u2014The Results Will Shock You!\",\n",
        "    \"Comelec Prepares for 2025 Elections With Improved Voter Registration System\",\n",
        "    \"PH Economy Grows by 5.8% in Third Quarter, Says PSA\",\n",
        "    \"A Mayor\u2019s Secret Finally Revealed\u2014The Whole Town Is Talking About It!\",\n",
        "    \"Here\u2019s Why Everyone Is Rushing to Try This New Food Trend in Quezon City!\",\n",
        "]\n",
        "\n",
        "# 4. Run predictions\n",
        "print(\"\\n--- Running Clickbait Prediction ---\")\n",
        "results = clickbait_detector(new_headlines)\n",
        "\n",
        "# 5. Print results\n",
        "for text, result in zip(new_headlines, results):\n",
        "    label = result[\"label\"]\n",
        "    # Depending on your dataset, 1 = clickbait, 0 = non-clickbait\n",
        "    prediction = \"Clickbait\" if label in [\"LABEL_1\", \"1\"] else \"Not Clickbait\"\n",
        "    print(f\"Headline: {text}\")\n",
        "    print(f\"   Prediction: {prediction} (Score: {result['score']:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SztUsApnrPud",
        "outputId": "a1daf9bd-813c-40c2-dd70-b56e64d5c686"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Clickbait Prediction ---\n",
            "Headline: MMDA Launches New Traffic Scheme to Ease Congestion Along EDSA\n",
            "   Prediction: Not Clickbait (Score: 1.0000)\n",
            "Headline: DepEd Confirms Opening of Classes Will Proceed as Scheduled\n",
            "   Prediction: Not Clickbait (Score: 1.0000)\n",
            "Headline: DOH Reports Steady Decline in Dengue Cases Nationwide\n",
            "   Prediction: Not Clickbait (Score: 1.0000)\n",
            "Headline: You Won\u2019t Believe What This Filipino Celebrity Did After Winning the Lottery!\n",
            "   Prediction: Clickbait (Score: 1.0000)\n",
            "Headline: This One Trick Can Help You Save Thousands on Your Meralco Bill!\n",
            "   Prediction: Clickbait (Score: 1.0000)\n",
            "Headline: Students in Manila Tried This Study Method\u2014The Results Will Shock You!\n",
            "   Prediction: Clickbait (Score: 0.9999)\n",
            "Headline: Comelec Prepares for 2025 Elections With Improved Voter Registration System\n",
            "   Prediction: Not Clickbait (Score: 1.0000)\n",
            "Headline: PH Economy Grows by 5.8% in Third Quarter, Says PSA\n",
            "   Prediction: Not Clickbait (Score: 1.0000)\n",
            "Headline: A Mayor\u2019s Secret Finally Revealed\u2014The Whole Town Is Talking About It!\n",
            "   Prediction: Clickbait (Score: 1.0000)\n",
            "Headline: Here\u2019s Why Everyone Is Rushing to Try This New Food Trend in Quezon City!\n",
            "   Prediction: Clickbait (Score: 1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# 1. Get predictions from the trainer on your evaluation set\n",
        "predictions = trainer.predict(tokenized_eval)\n",
        "\n",
        "# 2. Convert logits to predicted labels\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "# 3. Generate evaluation report\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Not Clickbait\", \"Clickbait\"]))\n",
        "\n",
        "# 4. Confusion matrix\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "8KQHtQP4rS6u",
        "outputId": "1ffbb2be-6c11-49a3-8a00-ec4dc938b917"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Classification Report ---\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Clickbait       1.00      0.99      1.00       248\n",
            "    Clickbait       0.99      1.00      1.00       252\n",
            "\n",
            "     accuracy                           1.00       500\n",
            "    macro avg       1.00      1.00      1.00       500\n",
            " weighted avg       1.00      1.00      1.00       500\n",
            "\n",
            "\n",
            "--- Confusion Matrix ---\n",
            "[[246   2]\n",
            " [  0 252]]\n"
          ]
        }
      ]
    }
  ]
}